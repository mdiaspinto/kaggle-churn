{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cc6bafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92a7e349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>level</th>\n",
       "      <th>userId</th>\n",
       "      <th>page</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>location</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>length</th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "      <th>time</th>\n",
       "      <th>registration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>paid</td>\n",
       "      <td>1749042</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>22683</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>278</td>\n",
       "      <td>524.32934</td>\n",
       "      <td>Ich mache einen Spiegel - Dream Part 4</td>\n",
       "      <td>Popol Vuh</td>\n",
       "      <td>2018-10-01 00:00:01</td>\n",
       "      <td>2018-08-08 13:22:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>M</td>\n",
       "      <td>paid</td>\n",
       "      <td>1749042</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>22683</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>279</td>\n",
       "      <td>178.02404</td>\n",
       "      <td>Monster (Album Version)</td>\n",
       "      <td>Skillet</td>\n",
       "      <td>2018-10-01 00:08:45</td>\n",
       "      <td>2018-08-08 13:22:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>M</td>\n",
       "      <td>paid</td>\n",
       "      <td>1749042</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>22683</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>280</td>\n",
       "      <td>232.61995</td>\n",
       "      <td>Seven Nation Army</td>\n",
       "      <td>The White Stripes</td>\n",
       "      <td>2018-10-01 00:11:43</td>\n",
       "      <td>2018-08-08 13:22:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>M</td>\n",
       "      <td>paid</td>\n",
       "      <td>1749042</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>22683</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>281</td>\n",
       "      <td>265.50812</td>\n",
       "      <td>Under The Bridge (Album Version)</td>\n",
       "      <td>Red Hot Chili Peppers</td>\n",
       "      <td>2018-10-01 00:15:35</td>\n",
       "      <td>2018-08-08 13:22:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>M</td>\n",
       "      <td>paid</td>\n",
       "      <td>1749042</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>22683</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>282</td>\n",
       "      <td>471.69261</td>\n",
       "      <td>Circlesong 6</td>\n",
       "      <td>Bobby McFerrin</td>\n",
       "      <td>2018-10-01 00:20:00</td>\n",
       "      <td>2018-08-08 13:22:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender level   userId      page  sessionId  \\\n",
       "0         M  paid  1749042  NextSong      22683   \n",
       "992       M  paid  1749042  NextSong      22683   \n",
       "1360      M  paid  1749042  NextSong      22683   \n",
       "1825      M  paid  1749042  NextSong      22683   \n",
       "2366      M  paid  1749042  NextSong      22683   \n",
       "\n",
       "                             location  itemInSession     length  \\\n",
       "0     Dallas-Fort Worth-Arlington, TX            278  524.32934   \n",
       "992   Dallas-Fort Worth-Arlington, TX            279  178.02404   \n",
       "1360  Dallas-Fort Worth-Arlington, TX            280  232.61995   \n",
       "1825  Dallas-Fort Worth-Arlington, TX            281  265.50812   \n",
       "2366  Dallas-Fort Worth-Arlington, TX            282  471.69261   \n",
       "\n",
       "                                        song                 artist  \\\n",
       "0     Ich mache einen Spiegel - Dream Part 4              Popol Vuh   \n",
       "992                  Monster (Album Version)                Skillet   \n",
       "1360                       Seven Nation Army      The White Stripes   \n",
       "1825        Under The Bridge (Album Version)  Red Hot Chili Peppers   \n",
       "2366                            Circlesong 6         Bobby McFerrin   \n",
       "\n",
       "                    time        registration  \n",
       "0    2018-10-01 00:00:01 2018-08-08 13:22:21  \n",
       "992  2018-10-01 00:08:45 2018-08-08 13:22:21  \n",
       "1360 2018-10-01 00:11:43 2018-08-08 13:22:21  \n",
       "1825 2018-10-01 00:15:35 2018-08-08 13:22:21  \n",
       "2366 2018-10-01 00:20:00 2018-08-08 13:22:21  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = '/Users/mdiaspinto/Documents/School/Python Data Science/Final Project/kaggle-churn'\n",
    "df_raw = pd.read_parquet(root + '/data/train.parquet')\n",
    "unused = ['status', 'firstName', 'lastName', 'ts', 'method', 'auth', 'userAgent']\n",
    "df_raw.drop(columns=unused, inplace=True)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8008ffb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>level</th>\n",
       "      <th>userId</th>\n",
       "      <th>page</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>location</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>length</th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "      <th>time</th>\n",
       "      <th>registration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M</td>\n",
       "      <td>free</td>\n",
       "      <td>1465194</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>22483</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>29</td>\n",
       "      <td>250.82730</td>\n",
       "      <td>Mockingbird</td>\n",
       "      <td>Eminem</td>\n",
       "      <td>2018-10-01 00:00:06</td>\n",
       "      <td>2018-09-27 17:29:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>M</td>\n",
       "      <td>free</td>\n",
       "      <td>1465194</td>\n",
       "      <td>Roll Advert</td>\n",
       "      <td>22483</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2018-10-01 00:00:28</td>\n",
       "      <td>2018-09-27 17:29:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>M</td>\n",
       "      <td>free</td>\n",
       "      <td>1465194</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>22483</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>31</td>\n",
       "      <td>355.78730</td>\n",
       "      <td>Thank You (Precious Memories Album Version)</td>\n",
       "      <td>Ray Boltz</td>\n",
       "      <td>2018-10-01 00:04:16</td>\n",
       "      <td>2018-09-27 17:29:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>M</td>\n",
       "      <td>free</td>\n",
       "      <td>1465194</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>22483</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>32</td>\n",
       "      <td>191.68608</td>\n",
       "      <td>Mathletics</td>\n",
       "      <td>Foals</td>\n",
       "      <td>2018-10-01 00:10:11</td>\n",
       "      <td>2018-09-27 17:29:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>M</td>\n",
       "      <td>free</td>\n",
       "      <td>1465194</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>22483</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>33</td>\n",
       "      <td>275.25179</td>\n",
       "      <td>Proceed</td>\n",
       "      <td>The Roots</td>\n",
       "      <td>2018-10-01 00:13:22</td>\n",
       "      <td>2018-09-27 17:29:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender level   userId         page  sessionId  \\\n",
       "7         M  free  1465194     NextSong      22483   \n",
       "54        M  free  1465194  Roll Advert      22483   \n",
       "477       M  free  1465194     NextSong      22483   \n",
       "1170      M  free  1465194     NextSong      22483   \n",
       "1552      M  free  1465194     NextSong      22483   \n",
       "\n",
       "                                   location  itemInSession     length  \\\n",
       "7     New York-Newark-Jersey City, NY-NJ-PA             29  250.82730   \n",
       "54    New York-Newark-Jersey City, NY-NJ-PA             30        NaN   \n",
       "477   New York-Newark-Jersey City, NY-NJ-PA             31  355.78730   \n",
       "1170  New York-Newark-Jersey City, NY-NJ-PA             32  191.68608   \n",
       "1552  New York-Newark-Jersey City, NY-NJ-PA             33  275.25179   \n",
       "\n",
       "                                             song     artist  \\\n",
       "7                                     Mockingbird     Eminem   \n",
       "54                                           None       None   \n",
       "477   Thank You (Precious Memories Album Version)  Ray Boltz   \n",
       "1170                                   Mathletics      Foals   \n",
       "1552                                      Proceed  The Roots   \n",
       "\n",
       "                    time        registration  \n",
       "7    2018-10-01 00:00:06 2018-09-27 17:29:36  \n",
       "54   2018-10-01 00:00:28 2018-09-27 17:29:36  \n",
       "477  2018-10-01 00:04:16 2018-09-27 17:29:36  \n",
       "1170 2018-10-01 00:10:11 2018-09-27 17:29:36  \n",
       "1552 2018-10-01 00:13:22 2018-09-27 17:29:36  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = '/Users/mdiaspinto/Documents/School/Python Data Science/Final Project/kaggle-churn'\n",
    "df_test = pd.read_parquet(root + '/data/test.parquet')\n",
    "df_test.drop(columns=unused, inplace=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5887e509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_builder(df: pd.DataFrame, cutoff_date: pd.Timestamp) -> pd.DataFrame:\n",
    "    \n",
    "    # Create a slice of the dataframe up to the cutoff date and makes userId the index\n",
    "    df_slice = df[df['time'] < cutoff_date].copy()\n",
    "    idx = pd.Index(np.sort(df['userId'].unique()), name='userId')\n",
    "    final_df = pd.DataFrame(index=idx)\n",
    "\n",
    "    # Get key features from users at cutoff date\n",
    "    user_group = df.groupby('userId')\n",
    "    final_df['level'] = user_group['level'].last().reindex(idx)\n",
    "    final_df['days_registered'] = \\\n",
    "        (cutoff_date.normalize() - user_group['registration'].min().reindex(idx).dt.normalize()).dt.days.astype(int)\n",
    "\n",
    "    # Group sessions and defines start and end for each one\n",
    "    session_group = df_slice.groupby(['userId', 'sessionId']).agg(\n",
    "        session_start=('time', 'min'),\n",
    "        session_end=('time', 'max'),\n",
    "        song_count=('song', 'count')\n",
    "    )\n",
    "\n",
    "    # Calculate session length in seconds\n",
    "    session_group['session_length'] = (\n",
    "    session_group['session_end'] - session_group['session_start']\n",
    "    ).dt.total_seconds()\n",
    "    \n",
    "    # Aggregate session statistics per user\n",
    "    session_stats = session_group.groupby('userId').agg(\n",
    "        num_sessions=('session_start', 'count'),\n",
    "        avg_songs_per_session=('song_count', 'mean'),\n",
    "        avg_session_length=('session_length', 'mean'),\n",
    "        days_since_last_session=('session_end', lambda x: (cutoff_date - x.max()).days),\n",
    "    )\n",
    "\n",
    "    # Convert to hours\n",
    "    session_stats['avg_session_length'] /= 3600\n",
    "\n",
    "    # Calculate proportion of activity on weekends\n",
    "    df_slice['day'] = df_slice['time'].dt.dayofweek\n",
    "    df_slice['weekend'] = df_slice['day'].isin([5, 6]).astype(int)\n",
    "    final_df['weekend_perc'] = (df_slice.groupby('userId')['weekend'].sum()\\\n",
    "        /df_slice.groupby('userId')['weekend'].count()).reindex(idx, fill_value=0)\n",
    "    final_df['weekend_perc'] *= 100\n",
    "\n",
    "    # Calculate proportion of weekend days in the target window\n",
    "    target_window = pd.date_range(start=cutoff_date + pd.Timedelta(days=1), periods=10)\n",
    "    weekend_window_perc = (target_window.dayofweek.isin([5, 6])).sum()\n",
    "    final_df['weekend_target_perc'] = weekend_window_perc * 10\n",
    "\n",
    "    # Build thumbs up and thumbs down features for last 5 and 10 sessions\n",
    "    for n_sessions in (5, 10):\n",
    "        # Find last N sessions per user\n",
    "        lastN = (\n",
    "            session_group.reset_index()[['userId', 'sessionId', 'session_end']]\n",
    "            .sort_values(['userId', 'session_end'])\n",
    "            .groupby('userId', as_index=False)\n",
    "            .tail(n_sessions)\n",
    "        )\n",
    "        lastN_keys = pd.MultiIndex.from_frame(lastN[['userId', 'sessionId']])\n",
    "\n",
    "        # Filter events to those sessions\n",
    "        df_lastN = (\n",
    "            df_slice.set_index(['userId', 'sessionId'])\n",
    "            .loc[lambda d: d.index.isin(lastN_keys)]\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        # Get user and page counts in last N sessions\n",
    "        page_group = (\n",
    "            df_lastN.groupby(['userId', 'page'])\n",
    "            .size()\n",
    "            .unstack()\n",
    "            .reindex(idx)\n",
    "            .fillna(0)\n",
    "        )\n",
    "\n",
    "        # Total songs in last N sessions\n",
    "        user_songs = (\n",
    "            session_group.loc[session_group.index.isin(lastN_keys), 'song_count']\n",
    "            .groupby(level=0)\n",
    "            .sum()\n",
    "            .reindex(idx, fill_value=0)\n",
    "        )\n",
    "        denom = user_songs.replace(0, 1)\n",
    "\n",
    "        suffix = f'_last{n_sessions}'\n",
    "\n",
    "        # Calculate several feature counts for last 5 sessions\n",
    "        if n_sessions == 5:\n",
    "            final_df['roll_advert_count_last5'] = (\n",
    "                page_group.get('Roll Advert', pd.Series(0, index=idx)).astype(int)\n",
    "            )\n",
    "            final_df['error_count_last5'] = (\n",
    "                page_group.get('Error', pd.Series(0, index=idx)).astype(int)\n",
    "            )\n",
    "            final_df['about_count_last5'] = (\n",
    "                page_group.get('About', pd.Series(0, index=idx)).astype(int)\n",
    "            )\n",
    "            final_df['add_playlist_count_last5'] = (\n",
    "                page_group.get('Add to Playlist', pd.Series(0, index=idx)).astype(int)\n",
    "            )\n",
    "\n",
    "            final_df['roll_advert_perc_last5'] = 100 * final_df['roll_advert_count_last5'] / denom\n",
    "            final_df['error_perc_last5'] = 100 * final_df['error_count_last5'] / denom\n",
    "            final_df['about_perc_last5'] = 100 * final_df['about_count_last5'] / denom\n",
    "            final_df['add_playlist_perc_last5'] = 100 * final_df['add_playlist_count_last5'] / denom\n",
    "            columns_drop = ['roll_advert_count_last5', 'error_count_last5', \\\n",
    "                            'about_count_last5', 'add_playlist_count_last5']\n",
    "            final_df.drop(columns = columns_drop, inplace=True)\n",
    "\n",
    "        final_df[f'thumbs_up_perc{suffix}'] = 100 * page_group.get('Thumbs Up', 0) / denom\n",
    "        final_df[f'thumbs_down_perc{suffix}'] = 100 * page_group.get('Thumbs Down', 0) / denom\n",
    "        final_df[f'thumbs_up_down_perc{suffix}'] = (\n",
    "            final_df[f'thumbs_up_perc{suffix}'] - final_df[f'thumbs_down_perc{suffix}']\n",
    "        )\n",
    "\n",
    "    # Calculate trends between last 5 and last 10 sessions\n",
    "    final_df['thumbs_up_trend'] = final_df['thumbs_up_perc_last5'] - final_df['thumbs_up_perc_last10']\n",
    "    final_df['thumbs_down_trend'] = final_df['thumbs_down_perc_last5'] - final_df['thumbs_down_perc_last10']\n",
    "    final_df['thumbs_up_down_trend'] = final_df['thumbs_up_perc_last5'] - final_df['thumbs_up_perc_last10']\n",
    "\n",
    "    # Calculate how long user has been premium on a proportion of observed activity\n",
    "    premium_count = (\n",
    "    df_slice.loc[df_slice[\"level\"].eq(\"paid\")]\n",
    "    .groupby(\"userId\")\n",
    "    .size()\n",
    "    .reindex(idx, fill_value=0)\n",
    "    )\n",
    "\n",
    "    events_user = (\n",
    "    df_slice.groupby(\"userId\")\n",
    "    .size()\n",
    "    .reindex(idx, fill_value=0)\n",
    "    )\n",
    "    final_df[\"paid_perc\"] = 100 * premium_count / events_user.replace(0, 1)\n",
    "\n",
    "    # Produce final dataframe for output\n",
    "    final_df = final_df.join(session_stats.reindex(idx))\n",
    "    num_features = ['num_sessions', 'avg_songs_per_session', \\\n",
    "                    'avg_session_length', 'days_since_last_session']\n",
    "    final_df[num_features] = final_df[num_features].fillna(0)\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b50e379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>days_registered</th>\n",
       "      <th>weekend_perc</th>\n",
       "      <th>weekend_target_perc</th>\n",
       "      <th>roll_advert_perc_last5</th>\n",
       "      <th>error_perc_last5</th>\n",
       "      <th>about_perc_last5</th>\n",
       "      <th>add_playlist_perc_last5</th>\n",
       "      <th>thumbs_up_perc_last5</th>\n",
       "      <th>thumbs_down_perc_last5</th>\n",
       "      <th>...</th>\n",
       "      <th>thumbs_down_perc_last10</th>\n",
       "      <th>thumbs_up_down_perc_last10</th>\n",
       "      <th>thumbs_up_trend</th>\n",
       "      <th>thumbs_down_trend</th>\n",
       "      <th>thumbs_up_down_trend</th>\n",
       "      <th>paid_perc</th>\n",
       "      <th>num_sessions</th>\n",
       "      <th>avg_songs_per_session</th>\n",
       "      <th>avg_session_length</th>\n",
       "      <th>days_since_last_session</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000025</th>\n",
       "      <td>paid</td>\n",
       "      <td>102</td>\n",
       "      <td>6.882793</td>\n",
       "      <td>30</td>\n",
       "      <td>0.553506</td>\n",
       "      <td>0.184502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.767528</td>\n",
       "      <td>4.059041</td>\n",
       "      <td>0.553506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331858</td>\n",
       "      <td>4.646018</td>\n",
       "      <td>-0.918836</td>\n",
       "      <td>0.221647</td>\n",
       "      <td>-0.918836</td>\n",
       "      <td>97.306733</td>\n",
       "      <td>17.0</td>\n",
       "      <td>97.764706</td>\n",
       "      <td>6.746552</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000035</th>\n",
       "      <td>paid</td>\n",
       "      <td>38</td>\n",
       "      <td>0.250627</td>\n",
       "      <td>30</td>\n",
       "      <td>1.246106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.623053</td>\n",
       "      <td>2.803738</td>\n",
       "      <td>8.411215</td>\n",
       "      <td>0.311526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308642</td>\n",
       "      <td>8.024691</td>\n",
       "      <td>0.077882</td>\n",
       "      <td>0.002885</td>\n",
       "      <td>0.077882</td>\n",
       "      <td>59.899749</td>\n",
       "      <td>7.0</td>\n",
       "      <td>46.285714</td>\n",
       "      <td>3.059206</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000083</th>\n",
       "      <td>paid</td>\n",
       "      <td>43</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>0.985222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.231527</td>\n",
       "      <td>4.187192</td>\n",
       "      <td>0.492611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406504</td>\n",
       "      <td>3.861789</td>\n",
       "      <td>-0.081101</td>\n",
       "      <td>0.086107</td>\n",
       "      <td>-0.081101</td>\n",
       "      <td>62.583893</td>\n",
       "      <td>11.0</td>\n",
       "      <td>45.545455</td>\n",
       "      <td>3.101742</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000103</th>\n",
       "      <td>paid</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>7.692308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.564103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.564103</td>\n",
       "      <td>...</td>\n",
       "      <td>2.564103</td>\n",
       "      <td>-2.564103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.764706</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>2.706667</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000164</th>\n",
       "      <td>paid</td>\n",
       "      <td>69</td>\n",
       "      <td>3.649635</td>\n",
       "      <td>30</td>\n",
       "      <td>3.167421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452489</td>\n",
       "      <td>3.167421</td>\n",
       "      <td>2.714932</td>\n",
       "      <td>0.904977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.598802</td>\n",
       "      <td>3.592814</td>\n",
       "      <td>-1.476685</td>\n",
       "      <td>0.306175</td>\n",
       "      <td>-1.476685</td>\n",
       "      <td>45.742092</td>\n",
       "      <td>9.0</td>\n",
       "      <td>37.111111</td>\n",
       "      <td>2.532253</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        level  days_registered  weekend_perc  weekend_target_perc  \\\n",
       "userId                                                              \n",
       "1000025  paid              102      6.882793                   30   \n",
       "1000035  paid               38      0.250627                   30   \n",
       "1000083  paid               43      0.000000                   30   \n",
       "1000103  paid               28      0.000000                   30   \n",
       "1000164  paid               69      3.649635                   30   \n",
       "\n",
       "         roll_advert_perc_last5  error_perc_last5  about_perc_last5  \\\n",
       "userId                                                                \n",
       "1000025                0.553506          0.184502          0.000000   \n",
       "1000035                1.246106          0.000000          0.623053   \n",
       "1000083                0.985222          0.000000          0.000000   \n",
       "1000103                7.692308          0.000000          0.000000   \n",
       "1000164                3.167421          0.000000          0.452489   \n",
       "\n",
       "         add_playlist_perc_last5  thumbs_up_perc_last5  \\\n",
       "userId                                                   \n",
       "1000025                 2.767528              4.059041   \n",
       "1000035                 2.803738              8.411215   \n",
       "1000083                 1.231527              4.187192   \n",
       "1000103                 2.564103              0.000000   \n",
       "1000164                 3.167421              2.714932   \n",
       "\n",
       "         thumbs_down_perc_last5  ...  thumbs_down_perc_last10  \\\n",
       "userId                           ...                            \n",
       "1000025                0.553506  ...                 0.331858   \n",
       "1000035                0.311526  ...                 0.308642   \n",
       "1000083                0.492611  ...                 0.406504   \n",
       "1000103                2.564103  ...                 2.564103   \n",
       "1000164                0.904977  ...                 0.598802   \n",
       "\n",
       "         thumbs_up_down_perc_last10  thumbs_up_trend  thumbs_down_trend  \\\n",
       "userId                                                                    \n",
       "1000025                    4.646018        -0.918836           0.221647   \n",
       "1000035                    8.024691         0.077882           0.002885   \n",
       "1000083                    3.861789        -0.081101           0.086107   \n",
       "1000103                   -2.564103         0.000000           0.000000   \n",
       "1000164                    3.592814        -1.476685           0.306175   \n",
       "\n",
       "         thumbs_up_down_trend  paid_perc  num_sessions  avg_songs_per_session  \\\n",
       "userId                                                                          \n",
       "1000025             -0.918836  97.306733          17.0              97.764706   \n",
       "1000035              0.077882  59.899749           7.0              46.285714   \n",
       "1000083             -0.081101  62.583893          11.0              45.545455   \n",
       "1000103              0.000000  11.764706           1.0              39.000000   \n",
       "1000164             -1.476685  45.742092           9.0              37.111111   \n",
       "\n",
       "         avg_session_length  days_since_last_session  \n",
       "userId                                                \n",
       "1000025            6.746552                      1.0  \n",
       "1000035            3.059206                      0.0  \n",
       "1000083            3.101742                      7.0  \n",
       "1000103            2.706667                     15.0  \n",
       "1000164            2.532253                      0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = feature_builder(df_raw, pd.Timestamp('2018-10-20'))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb4fef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_builder(df: pd.DataFrame,\n",
    "                 cutoff_date: pd.Timestamp,\n",
    "                 window_size: int = 10,\n",
    "                 buffer: int = 3) -> pd.Series:\n",
    "    \n",
    "    # Define the time window including buffer period\n",
    "    window_end = cutoff_date + pd.Timedelta(days=window_size)\n",
    "    buffer_end = window_end + pd.Timedelta(days=buffer)\n",
    "    window_users = df.loc[df['time'] <= cutoff_date, 'userId'].unique()\n",
    "\n",
    "    # Get the cancellation time for each user\n",
    "    cancel_time = (\n",
    "        df.loc[df['page'] == 'Cancellation Confirmation']\n",
    "          .groupby('userId')['time']\n",
    "          .min()\n",
    "          .reindex(window_users)\n",
    "    )\n",
    "\n",
    "    # Set target labels based on cancellation time\n",
    "    y = pd.Series(0, index=window_users, name='target')\n",
    "    y[cancel_time <= cutoff_date] = np.nan\n",
    "    y[(cancel_time > window_end) & (cancel_time <= buffer_end)] = np.nan\n",
    "    y[(cancel_time > cutoff_date) & (cancel_time <= window_end)] = 1\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2376af76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1749042    1.0\n",
       "1563081    0.0\n",
       "1697168    0.0\n",
       "1222580    NaN\n",
       "1714398    0.0\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = label_builder(df_raw, pd.Timestamp('2018-10-20'))\n",
    "test_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d85bda93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating rolling training data from 2018-10-01 to 2018-11-05...\n",
      "  - Processing window: 2018-10-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/69/x1vfxvpd1_q07my0mb9rc8tm0000gn/T/ipykernel_19270/2989908734.py:140: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  final_df[num_features] = final_df[num_features].fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Processing window: 2018-10-08\n",
      "  - Processing window: 2018-10-15\n",
      "  - Processing window: 2018-10-22\n",
      "  - Processing window: 2018-10-29\n",
      "  - Processing window: 2018-11-05\n",
      "Dropping correlated (>0.95): ['thumbs_up_perc_last10', 'thumbs_down_perc_last10', 'thumbs_up_down_perc_last10', 'thumbs_up_down_trend', 'avg_session_length']\n",
      "Total Samples: 72948\n"
     ]
    }
   ],
   "source": [
    "def window_builder(df: pd.DataFrame,\n",
    "                start_date,\n",
    "                end_date,\n",
    "                *,\n",
    "                step_days: int = 7,\n",
    "                window_size: int = 10,\n",
    "                buffer: int = 3,\n",
    "                corr_threshold: float = 0.95,\n",
    "                categorical_cols=('level',),\n",
    "                verbose: bool = True):\n",
    "\n",
    "    start_date = pd.Timestamp(start_date)\n",
    "    end_date = pd.Timestamp(end_date)\n",
    "\n",
    "    all_windows = []\n",
    "    current = start_date\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Generating rolling training data from {start_date.date()} to {end_date.date()}...')\n",
    "\n",
    "    while current <= end_date:\n",
    "        if verbose:\n",
    "            print(f'  - Processing window: {current.date()}')\n",
    "\n",
    "        feats = feature_builder(df, current)\n",
    "        labels = label_builder(df, current, window_size=window_size, buffer=buffer)\n",
    "\n",
    "        labels = labels.reindex(feats.index)\n",
    "        mask = labels.notna()\n",
    "\n",
    "        window = feats.loc[mask].copy()\n",
    "        window['target'] = labels.loc[mask].astype(int)\n",
    "        window['snapshot_date'] = current\n",
    "\n",
    "        all_windows.append(window)\n",
    "        current += pd.Timedelta(days=step_days)\n",
    "\n",
    "    df_window = pd.concat(all_windows, axis=0)\n",
    "\n",
    "    # Drop userId index\n",
    "    groups = df_window.index.to_numpy()\n",
    "    df_window = df_window.reset_index(drop=True)\n",
    "\n",
    "    # Define X and y\n",
    "    X = df_window.drop(columns=['target', 'snapshot_date'], errors='ignore')\n",
    "    y = df_window['target'].astype(int)\n",
    "\n",
    "    # Mark categoricals as category dtype\n",
    "    for c in categorical_cols:\n",
    "        if c in X.columns:\n",
    "            X[c] = X[c].astype('category')\n",
    "\n",
    "    # Drop highly correlated numeric columns\n",
    "    dropped_cols = []\n",
    "    if corr_threshold is not None:\n",
    "        X_num = X.select_dtypes(include=[np.number])\n",
    "        if X_num.shape[1] >= 2:\n",
    "            corr = X_num.corr().abs()\n",
    "            upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "            dropped_cols = [col for col in upper.columns if (upper[col] > corr_threshold).any()]\n",
    "            if verbose:\n",
    "                print(f'Dropping correlated (>{corr_threshold}): {dropped_cols}')\n",
    "            X = X.drop(columns=dropped_cols, errors='ignore')\n",
    "\n",
    "    return X, y, groups, df_window\n",
    "\n",
    "\n",
    "start_dt = pd.Timestamp('2018-10-01')\n",
    "end_dt = pd.Timestamp('2018-11-05')\n",
    "\n",
    "X_window, y_window, groups_window, df_window = window_builder(\n",
    "    df_raw,\n",
    "    start_dt,\n",
    "    end_dt\n",
    " )\n",
    "\n",
    "print(f'Total Samples: {len(df_window)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "02dd7397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Training Model 1/5 (LightGBM)...\n",
      "[LightGBM] [Info] Number of positive: 4059, number of negative: 68889\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3420\n",
      "[LightGBM] [Info] Number of data points in the train set: 72948, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.055642 -> initscore=-2.831560\n",
      "[LightGBM] [Info] Start training from score -2.831560\n",
      "  - Training Model 2/5 (LightGBM)...\n",
      "[LightGBM] [Info] Number of positive: 4059, number of negative: 68889\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3420\n",
      "[LightGBM] [Info] Number of data points in the train set: 72948, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.055642 -> initscore=-2.831560\n",
      "[LightGBM] [Info] Start training from score -2.831560\n",
      "  - Training Model 3/5 (LightGBM)...\n",
      "[LightGBM] [Info] Number of positive: 4059, number of negative: 68889\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3420\n",
      "[LightGBM] [Info] Number of data points in the train set: 72948, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.055642 -> initscore=-2.831560\n",
      "[LightGBM] [Info] Start training from score -2.831560\n",
      "  - Training Model 4/5 (LightGBM)...\n",
      "[LightGBM] [Info] Number of positive: 4059, number of negative: 68889\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006006 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3420\n",
      "[LightGBM] [Info] Number of data points in the train set: 72948, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.055642 -> initscore=-2.831560\n",
      "[LightGBM] [Info] Start training from score -2.831560\n",
      "  - Training Model 5/5 (LightGBM)...\n",
      "[LightGBM] [Info] Number of positive: 4059, number of negative: 68889\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3420\n",
      "[LightGBM] [Info] Number of data points in the train set: 72948, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.055642 -> initscore=-2.831560\n",
      "[LightGBM] [Info] Start training from score -2.831560\n"
     ]
    }
   ],
   "source": [
    "# Defining our model's params\n",
    "lgb_params = {\n",
    "    'objective': 'binary',\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'n_jobs': -1,\n",
    "    'is_unbalance': True\n",
    "}\n",
    "\n",
    "models = []\n",
    "for i in range(5):\n",
    "    print(f'  - Training Model {1+i}/5 (LightGBM)...')\n",
    "    model = lgb.LGBMClassifier(**lgb_params, random_state=42+i)\n",
    "    model.fit(X_window, y_window)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eec6613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using threshold: 0.51\n",
      "Predicted positives: 1331 out of 2904\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.52\n",
    "\n",
    "# Generate features for test set\n",
    "test_date = df_test['time'].max()\n",
    "X_test = feature_builder(df_test, test_date)\n",
    "\n",
    "# Match training dtype / categories for categoricals\n",
    "if 'level' in X_test.columns:\n",
    "    X_test['level'] = X_test['level'].astype('category')\n",
    "    if 'level' in X_window.columns and str(X_window['level'].dtype) == 'category':\n",
    "        X_test['level'] = X_test['level'].cat.set_categories(X_window['level'].cat.categories)\n",
    "\n",
    "model_test = models[0]\n",
    "trained_feature_names = list(model_test.booster_.feature_name())\n",
    "\n",
    "# Align columns to training (order + missing cols filled with 0)\n",
    "X_final = X_test.reindex(columns=trained_feature_names, fill_value=0)\n",
    "\n",
    "total_prob = np.zeros(len(X_final), dtype=float)\n",
    "for m in models:\n",
    "    prob = m.predict_proba(X_final)[:, 1]\n",
    "    total_prob += prob\n",
    "\n",
    "test_probs = total_prob / len(models)\n",
    "predict_labels = (test_probs >= threshold).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({'id': X_test.index, 'target': predict_labels})\n",
    "submission.to_csv(root + '/data/submission_nopipeline.csv', index=False)\n",
    "\n",
    "print('Using threshold:', float(threshold))\n",
    "print('Predicted positives:', int(predict_labels.sum()), 'out of', int(len(predict_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef2e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'].count()\n",
    "submission['target'].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
