{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b5cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import src.preprocessing\n",
    "from importlib import reload\n",
    "reload(src.preprocessing)\n",
    "\n",
    "from typing import Union\n",
    "from src.preprocessing import (\n",
    "    compute_cancellation, \n",
    "    aggregate_user_day_activity, \n",
    "    add_rolling_averages\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca68f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/Users/mdiaspinto/Documents/School/Python Data Science/Final Project/kaggle-churn'\n",
    "df = pd.read_parquet(root + '/data/train.parquet')\n",
    "\n",
    "object_cols = df.select_dtypes(include=\"object\").columns\n",
    "df[object_cols] = df[object_cols].astype(\"category\")\n",
    "df.drop(columns=['gender', 'firstName', 'lastName', 'location', 'userAgent'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58236d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = aggregate_user_day_activity(df)\n",
    "df_new['userId'] = df_new['userId'].astype(int)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583bdd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = add_rolling_averages(df_new, columns=['Add Friend', 'Add to Playlist', 'Thumbs Down', 'Thumbs Up', 'Error'], n=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72516f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "denominator = df_new['thumbs_up_avg_7d'] + df_new['thumbs_down_avg_7d']\n",
    "df_new['thumbs_ratio_7d'] = df_new['thumbs_up_avg_7d'] / denominator.replace(0, pd.NA)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1131c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dates = sorted(df_new['date'].unique())\n",
    "print(f\"Computing cancellation targets for {len(unique_dates)} unique dates...\")\n",
    "\n",
    "cancellation_targets = []\n",
    "\n",
    "for present_date in unique_dates:\n",
    "    target_df = compute_cancellation(df, present_time=present_date, window_days=10)\n",
    "    target_df['date'] = present_date\n",
    "    cancellation_targets.append(target_df)\n",
    "\n",
    "target_by_date = pd.concat(cancellation_targets, ignore_index=True)\n",
    "target_by_date = target_by_date.rename(columns={'userId': 'userId', 'cancellation_confirmed': 'churn_status'})\n",
    "\n",
    "print(f\"\\nCancellation targets shape: {target_by_date.shape}\")\n",
    "print(f\"Sample:\")\n",
    "print(target_by_date.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09f0107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = pd.read_csv(root + '/data/df_transformed.csv')\n",
    "target_by_date = pd.read_csv(root + '/data/churn_status.csv')\n",
    "\n",
    "df_new.to_csv(root + '/data/df_transformed.csv', index=False)\n",
    "# target_by_date.to_csv(root + '/data/churn_status.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cee51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['date'] = pd.to_datetime(df_new['date'])\n",
    "target_by_date['date'] = pd.to_datetime(target_by_date['date'])\n",
    "df_train = df_new.merge(target_by_date, on=['userId', 'date'], how='left')\n",
    "\n",
    "print(f\"\\nChurn distribution:\")\n",
    "print(df_train['churn_status'].value_counts())\n",
    "print(f\"\\nSample:\")\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc20b819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (780912, 30)\n",
      "Test set size: (195228, 30)\n",
      "Feature columns (30): ['About', 'Add Friend', 'Add to Playlist', 'Cancel', 'Downgrade', 'Error', 'Help', 'Home', 'Logout', 'NextSong', 'Roll Advert', 'Save Settings', 'Settings', 'Submit Downgrade', 'Submit Upgrade', 'Thumbs Down', 'Thumbs Up', 'Upgrade', 'event_count', 'session_count', 'active_flag', 'events_per_session', 'level', 'days_since_registration', 'add_friend_avg_7d', 'add_to_playlist_avg_7d', 'thumbs_down_avg_7d', 'thumbs_up_avg_7d', 'error_avg_7d', 'thumbs_ratio_7d']\n",
      "\n",
      "Data types after fixes:\n",
      "About                        int64\n",
      "Add Friend                   int64\n",
      "Add to Playlist              int64\n",
      "Cancel                       int64\n",
      "Downgrade                    int64\n",
      "Error                        int64\n",
      "Help                         int64\n",
      "Home                         int64\n",
      "Logout                       int64\n",
      "NextSong                     int64\n",
      "Roll Advert                  int64\n",
      "Save Settings                int64\n",
      "Settings                     int64\n",
      "Submit Downgrade             int64\n",
      "Submit Upgrade               int64\n",
      "Thumbs Down                  int64\n",
      "Thumbs Up                    int64\n",
      "Upgrade                      int64\n",
      "event_count                  int64\n",
      "session_count                int64\n",
      "active_flag                  int64\n",
      "events_per_session         float64\n",
      "level                        int64\n",
      "days_since_registration      int64\n",
      "add_friend_avg_7d          float64\n",
      "add_to_playlist_avg_7d     float64\n",
      "thumbs_down_avg_7d         float64\n",
      "thumbs_up_avg_7d           float64\n",
      "error_avg_7d               float64\n",
      "thumbs_ratio_7d            float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Split data and define variables for modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define feature columns (exclude userId, date, and target)\n",
    "feature_cols = [col for col in df_train.columns if col not in ['userId', 'date', 'churn_status']]\n",
    "\n",
    "# Separate features and target\n",
    "X = df_train[feature_cols].copy()\n",
    "y = df_train['churn_status']\n",
    "\n",
    "# Fix data types for XGBoost compatibility\n",
    "# Convert 'level' category to numeric (0 for 'free', 1 for 'paid')\n",
    "if 'level' in X.columns:\n",
    "    X['level'] = (X['level'] == 'paid').astype(int)\n",
    "\n",
    "# Convert thumbs_ratio_7d from object to float\n",
    "if 'thumbs_ratio_7d' in X.columns:\n",
    "    X['thumbs_ratio_7d'] = pd.to_numeric(X['thumbs_ratio_7d'], errors='coerce').fillna(0)\n",
    "\n",
    "# Split into train and test sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "print(f\"Feature columns ({len(feature_cols)}): {feature_cols}\")\n",
    "print(f\"\\nData types after fixes:\")\n",
    "print(X_train.dtypes)\n",
    "\n",
    "# For predictions on final test data\n",
    "X_test_pred = X_test\n",
    "df_test_final = df_train.iloc[X_test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a763e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated scale_pos_weight: 24.92\n",
      "Training XGBoost optimized for balanced accuracy...\n",
      "Model training complete!\n",
      "\n",
      "=== XGBoost Performance ===\n",
      "\n",
      "=== Model Performance ===\n",
      "Balanced Accuracy: 0.6771\n",
      "ROC-AUC Score: 0.7416\n",
      "\n",
      "Confusion Matrix:\n",
      "[[137279  50416]\n",
      " [  2842   4691]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.73      0.84    187695\n",
      "           1       0.09      0.62      0.15      7533\n",
      "\n",
      "    accuracy                           0.73    195228\n",
      "   macro avg       0.53      0.68      0.49    195228\n",
      "weighted avg       0.95      0.73      0.81    195228\n",
      "\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                    feature  importance\n",
      "18              event_count    0.376100\n",
      "3                    Cancel    0.307514\n",
      "26       thumbs_down_avg_7d    0.104401\n",
      "25   add_to_playlist_avg_7d    0.031323\n",
      "7                      Home    0.021535\n",
      "27         thumbs_up_avg_7d    0.016635\n",
      "22                    level    0.016474\n",
      "19            session_count    0.013189\n",
      "10              Roll Advert    0.012596\n",
      "23  days_since_registration    0.011400\n",
      "\n",
      "Loading test data and applying preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mdiaspinto/Documents/School/Python Data Science/Final Project/kaggle-churn/src/preprocessing.py:155: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  per_day_counts = df_copy.groupby([user_col, 'date']).size().reset_index(name='event_count')\n",
      "/Users/mdiaspinto/Documents/School/Python Data Science/Final Project/kaggle-churn/src/preprocessing.py:157: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  session_counts = df_copy.groupby([user_col, 'date'])['sessionId'].nunique().reset_index(name='session_count')\n",
      "/Users/mdiaspinto/Documents/School/Python Data Science/Final Project/kaggle-churn/src/preprocessing.py:164: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  user_registration = df_copy.groupby(user_col)[registration_col].first().reset_index()\n",
      "/Users/mdiaspinto/Documents/School/Python Data Science/Final Project/kaggle-churn/src/preprocessing.py:175: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  level_per_day = df_copy.groupby([user_col, 'date'])[level_col].last().reset_index()\n",
      "/Users/mdiaspinto/Documents/School/Python Data Science/Final Project/kaggle-churn/src/preprocessing.py:181: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_aggregated = df_copy.groupby([user_col, 'date', page_col]).size().unstack(fill_value=0).reset_index()\n",
      "/Users/mdiaspinto/Documents/School/Python Data Science/Final Project/kaggle-churn/src/preprocessing.py:207: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for user_id, user_data in df_aggregated.groupby(user_col):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test submission matrix shape: (2904, 30)\n",
      "Test data types: int64      23\n",
      "float64     7\n",
      "Name: count, dtype: int64\n",
      "Making predictions...\n",
      "Predictions shape: (2904,)\n",
      "Prediction distribution:\n",
      "0    2105\n",
      "1     799\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Submission dataframe shape: (2904, 2)\n",
      "Sample submissions:\n",
      "        id  target\n",
      "0  1995115       0\n",
      "1  1993285       0\n",
      "2  1979129       0\n",
      "3  1997769       0\n",
      "4  1997880       0\n",
      "5  1985914       0\n",
      "6  1987068       0\n",
      "7  1988412       1\n",
      "8  1994524       1\n",
      "9  1988592       0\n",
      "Submission target distribution:\n",
      "target\n",
      "0    2105\n",
      "1     799\n",
      "Name: count, dtype: int64\n",
      "Saved submission to /Users/mdiaspinto/Documents/School/Python Data Science/Final Project/kaggle-churn/data/submissionx.csv\n"
     ]
    }
   ],
   "source": [
    "# Train XGBoost and generate predictions\n",
    "import src.modeling\n",
    "reload(src.modeling)\n",
    "from src.modeling import (\n",
    "    train_xgboost,\n",
    "    evaluate_model,\n",
    "    get_feature_importance,\n",
    "    make_predictions,\n",
    "    create_submission,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_model = train_xgboost(X_train, y_train)\n",
    "print(\"\\n=== XGBoost Performance ===\")\n",
    "xgb_results = evaluate_model(xgb_model, X_test, y_test)\n",
    "xgb_feature_importance = get_feature_importance(xgb_model, feature_cols, top_n=10)\n",
    "\n",
    "# Load and preprocess test data to mirror train\n",
    "print(\"\\nLoading test data and applying preprocessing...\")\n",
    "df_test_raw = pd.read_parquet(root + '/data/test.parquet')\n",
    "\n",
    "object_cols_test = df_test_raw.select_dtypes(include=\"object\").columns\n",
    "df_test_raw[object_cols_test] = df_test_raw[object_cols_test].astype(\"category\")\n",
    "\n",
    "df_test_raw = df_test_raw.drop(columns=['gender', 'firstName', 'lastName', 'location', 'userAgent'], errors='ignore')\n",
    "\n",
    "df_test_agg = aggregate_user_day_activity(df_test_raw)\n",
    "df_test_agg['userId'] = df_test_agg['userId'].astype(int)\n",
    "\n",
    "df_test_agg = add_rolling_averages(\n",
    "    df_test_agg,\n",
    "    columns=['Add Friend', 'Add to Playlist', 'Thumbs Down', 'Thumbs Up', 'Error'],\n",
    "    n=7\n",
    ")\n",
    "\n",
    "denominator_test = df_test_agg['thumbs_up_avg_7d'] + df_test_agg['thumbs_down_avg_7d']\n",
    "df_test_agg['thumbs_ratio_7d'] = df_test_agg['thumbs_up_avg_7d'] / denominator_test.replace(0, pd.NA)\n",
    "\n",
    "# Use the most recent date per user for prediction\n",
    "df_test_latest = df_test_agg.sort_values('date').groupby('userId', as_index=False).tail(1)\n",
    "\n",
    "# Align test features to the training feature set\n",
    "X_test_submission = df_test_latest.reindex(columns=feature_cols, fill_value=0)\n",
    "\n",
    "# Apply same data type fixes as training data\n",
    "if 'level' in X_test_submission.columns:\n",
    "    X_test_submission['level'] = (X_test_submission['level'] == 'paid').astype(int)\n",
    "\n",
    "if 'thumbs_ratio_7d' in X_test_submission.columns:\n",
    "    X_test_submission['thumbs_ratio_7d'] = pd.to_numeric(X_test_submission['thumbs_ratio_7d'], errors='coerce').fillna(0)\n",
    "\n",
    "print(f\"Test submission matrix shape: {X_test_submission.shape}\")\n",
    "print(f\"Test data types: {X_test_submission.dtypes.value_counts()}\")\n",
    "\n",
    "# Predict and write submission\n",
    "xgb_test_predictions, xgb_test_proba = make_predictions(xgb_model, X_test_submission)\n",
    "xgb_submission_final = create_submission(\n",
    "    df_test_latest['userId'].values,\n",
    "    xgb_test_predictions,\n",
    "    output_path=root + '/data/submissionx.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57de9def",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
