{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b5cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import src.preprocessing\n",
    "from importlib import reload\n",
    "reload(src.preprocessing)\n",
    "\n",
    "from typing import Union\n",
    "from src.preprocessing import (\n",
    "    compute_cancellation, \n",
    "    aggregate_user_day_activity, \n",
    "    add_days_since, \n",
    "    add_rolling_averages,\n",
    "    add_thumbs_ratio,\n",
    "    add_days_active_last_n_days\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca68f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/Users/mdiaspinto/Documents/School/Python Data Science/Final Project/kaggle-churn'\n",
    "df = pd.read_parquet(root + '/data/train.parquet')\n",
    "\n",
    "object_cols = df.select_dtypes(include=\"object\").columns\n",
    "df[object_cols] = df[object_cols].astype(\"category\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58236d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = aggregate_user_day_activity(df)\n",
    "df_new = add_rolling_averages(df_new, columns=['Add Friend', 'Add to Playlist', 'Thumbs Down', 'Thumbs Up'], n=30)\n",
    "df_new = add_rolling_averages(df_new, columns=['Thumbs Down', 'Thumbs Up', 'Error'], n=7)\n",
    "df_new['thumbs_ratio'] = df_new['thumbs_up_avg_7d'] / (df_new['thumbs_up_avg_7d'] + df_new['thumbs_down_avg_7d'])\n",
    "df_new.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1131c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dates = sorted(df_new['date'].unique())\n",
    "print(f\"Computing cancellation targets for {len(unique_dates)} unique dates...\")\n",
    "\n",
    "cancellation_targets = []\n",
    "\n",
    "for present_date in unique_dates:\n",
    "    target_df = compute_cancellation(df, present_time=present_date, window_days=10)\n",
    "    target_df['date'] = present_date\n",
    "    cancellation_targets.append(target_df)\n",
    "\n",
    "target_by_date = pd.concat(cancellation_targets, ignore_index=True)\n",
    "target_by_date = target_by_date.rename(columns={'userId': 'userId', 'cancellation_confirmed': 'churn_status'})\n",
    "\n",
    "print(f\"\\nCancellation targets shape: {target_by_date.shape}\")\n",
    "print(f\"Sample:\")\n",
    "print(target_by_date.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09f0107",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_csv(root + '/data/df_transformed.csv')\n",
    "target_by_date = pd.read_csv(root + '/data/churn_status.csv')\n",
    "\n",
    "# df_new.to_csv(root + '/data/df_transformed.csv', index=False)\n",
    "# target_by_date.to_csv(root + '/data/churn_status.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cee51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_new.merge(target_by_date, on=['userId', 'date'], how='left')\n",
    "\n",
    "print(f\"df_train shape: {df_train.shape}\")\n",
    "print(f\"Columns: {df_train.columns.tolist()}\")\n",
    "print(f\"\\nChurn distribution:\")\n",
    "print(df_train['churn_status'].value_counts())\n",
    "print(f\"\\nSample:\")\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50573aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest model to predict churn_status\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Prepare data: drop rows with NaN in target\n",
    "df_model = df_train.dropna(subset=['churn_status']).copy()\n",
    "print(f\"Training data shape after dropping NaN targets: {df_model.shape}\")\n",
    "\n",
    "# Separate features and target\n",
    "# Exclude userId, date, and churn_status from features\n",
    "exclude_cols = ['userId', 'date', 'churn_status']\n",
    "feature_cols = [col for col in df_model.columns if col not in exclude_cols]\n",
    "\n",
    "# One-hot encode categorical features and fill remaining NaNs\n",
    "obj_cols = [c for c in feature_cols if df_model[c].dtype == 'object']\n",
    "X = pd.get_dummies(df_model[feature_cols], columns=obj_cols, drop_first=True).fillna(0)\n",
    "feature_cols = X.columns.tolist()\n",
    "y = df_model['churn_status'].astype(int)\n",
    "\n",
    "print(f\"\\nFeatures: {len(feature_cols)} columns\")\n",
    "print(f\"Feature columns: {feature_cols}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\nTrain set: {X_train.shape}, Test set: {X_test.shape}\")\n",
    "\n",
    "# Train Random Forest\n",
    "print(\"\\nTraining Random Forest...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10, n_jobs=-1, class_weight='balanced')\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== Model Performance ===\")\n",
    "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcdeb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and transform test data with the same pipeline as training data\n",
    "print(\"Loading test data...\")\n",
    "df_test = pd.read_parquet(root + '/data/test.parquet')\n",
    "print(f\"Test data shape: {df_test.shape}\")\n",
    "print(f\"Date range: {df_test['time'].min()} to {df_test['time'].max()}\")\n",
    "\n",
    "# Apply the same transformations\n",
    "print(\"\\nApplying transformations to test data...\")\n",
    "\n",
    "# 1. Aggregate by user and day\n",
    "df_test_agg = aggregate_user_day_activity(df_test, fill_missing_days=True)\n",
    "print(f\"After aggregation: {df_test_agg.shape}\")\n",
    "print(f\"Available columns: {df_test_agg.columns.tolist()}\")\n",
    "\n",
    "# 2. Add days since metrics - only track columns that exist in test data\n",
    "available_tracking_cols = []\n",
    "for col in ['Submit Downgrade', 'Submit Upgrade', 'Cancel']:\n",
    "    if col in df_test_agg.columns:\n",
    "        available_tracking_cols.append(col)\n",
    "\n",
    "if available_tracking_cols:\n",
    "    df_test_agg = add_days_since(df_test_agg, columns_to_track=available_tracking_cols)\n",
    "    print(f\"After days_since: {df_test_agg.shape}\")\n",
    "else:\n",
    "    print(\"No tracking columns found, skipping days_since\")\n",
    "\n",
    "# 3. Add 30-day rolling averages\n",
    "activity_cols_30 = ['Add Friend', 'Add to Playlist', 'Thumbs Down', 'Thumbs Up']\n",
    "available_cols_30 = [col for col in activity_cols_30 if col in df_test_agg.columns]\n",
    "if available_cols_30:\n",
    "    df_test_agg = add_rolling_averages(df_test_agg, columns=available_cols_30, n=30)\n",
    "    print(f\"After 30d rolling averages: {df_test_agg.shape}\")\n",
    "\n",
    "# 4. Add 7-day rolling averages\n",
    "activity_cols_7 = ['Thumbs Down', 'Thumbs Up', 'Error']\n",
    "available_cols_7 = [col for col in activity_cols_7 if col in df_test_agg.columns]\n",
    "if available_cols_7:\n",
    "    df_test_agg = add_rolling_averages(df_test_agg, columns=available_cols_7, n=7)\n",
    "    print(f\"After 7d rolling averages: {df_test_agg.shape}\")\n",
    "\n",
    "# 5. Add new features\n",
    "df_test_agg = add_thumbs_ratio(df_test_agg, thumbs_up_col='thumbs_up_avg_7d', thumbs_down_col='thumbs_down_avg_7d')\n",
    "df_test_agg = add_days_active_last_n_days(df_test_agg, n_days=30)\n",
    "\n",
    "print(\"\\nTest data ready for prediction!\")\n",
    "print(f\"Final test features shape: {df_test_agg.shape}\")\n",
    "print(f\"Columns: {df_test_agg.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148ebd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data using the most recent data for each user\n",
    "# The 10-day churn window starts on the last date and extends 10 days forward\n",
    "from src.modeling import prepare_test_data, make_predictions, create_submission\n",
    "from datetime import timedelta\n",
    "\n",
    "print(\"Preparing test data for model prediction...\")\n",
    "\n",
    "# Get the last date in test data\n",
    "last_date = df_test_agg['date'].max()\n",
    "\n",
    "# Define the 10-day prediction window (for churn prediction)\n",
    "window_end = last_date + timedelta(days=9)  # 10 days total (inclusive of last_date)\n",
    "print(f\"Churn prediction window: {last_date} to {window_end}\")\n",
    "\n",
    "# Prepare test data\n",
    "X_test_pred, df_test_final = prepare_test_data(df_test_agg, feature_cols, last_date=last_date)\n",
    "\n",
    "# Make predictions\n",
    "test_predictions, test_predictions_proba = make_predictions(rf_model, X_test_pred)\n",
    "\n",
    "# Create and save submission\n",
    "submission = create_submission(\n",
    "    df_test_final['userId'].values,\n",
    "    test_predictions,\n",
    "    output_path=root + '/data/submission.csv'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a763e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost model\n",
    "reload(src.modeling)\n",
    "from src.modeling import train_xgboost, evaluate_model, get_feature_importance\n",
    "\n",
    "# Train XGBoost with the same train/test split\n",
    "xgb_model = train_xgboost(X_train, y_train)\n",
    "\n",
    "# Evaluate XGBoost\n",
    "print(\"\\n=== XGBoost Performance ===\")\n",
    "xgb_results = evaluate_model(xgb_model, X_test, y_test)\n",
    "\n",
    "# Feature importance for XGBoost\n",
    "xgb_feature_importance = get_feature_importance(xgb_model, feature_cols, top_n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80758425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make XGBoost predictions on test data\n",
    "print(\"Making XGBoost predictions...\")\n",
    "\n",
    "# Use the same prepared test data\n",
    "xgb_predictions, xgb_predictions_proba = make_predictions(xgb_model, X_test_pred)\n",
    "\n",
    "# Create and save XGBoost submission\n",
    "xgb_submission = create_submission(\n",
    "    df_test_final['userId'].values,\n",
    "    xgb_predictions,\n",
    "    output_path=root + '/data/submissionx.csv'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
