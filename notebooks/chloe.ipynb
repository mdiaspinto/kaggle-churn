{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a0e0e15cb7e692e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T12:56:28.322506Z",
     "start_time": "2025-12-09T12:56:28.108338Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import src.preprocessing\n",
    "from importlib import reload\n",
    "reload(src.preprocessing)\n",
    "\n",
    "from typing import Union\n",
    "from src.preprocessing import (\n",
    "    compute_cancellation,\n",
    "    aggregate_user_day_activity,\n",
    "    add_rolling_averages\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b4ab6fdc1fca311",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T12:57:07.408832Z",
     "start_time": "2025-12-09T12:56:28.332397Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>gender</th>\n",
       "      <th>firstName</th>\n",
       "      <th>level</th>\n",
       "      <th>lastName</th>\n",
       "      <th>userId</th>\n",
       "      <th>ts</th>\n",
       "      <th>auth</th>\n",
       "      <th>page</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>location</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>method</th>\n",
       "      <th>length</th>\n",
       "      <th>song</th>\n",
       "      <th>artist</th>\n",
       "      <th>time</th>\n",
       "      <th>registration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>M</td>\n",
       "      <td>Shlok</td>\n",
       "      <td>paid</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>1749042</td>\n",
       "      <td>1538352001000</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>22683</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>278</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>PUT</td>\n",
       "      <td>524.32934</td>\n",
       "      <td>Ich mache einen Spiegel - Dream Part 4</td>\n",
       "      <td>Popol Vuh</td>\n",
       "      <td>2018-10-01 00:00:01</td>\n",
       "      <td>2018-08-08 13:22:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>200</td>\n",
       "      <td>M</td>\n",
       "      <td>Shlok</td>\n",
       "      <td>paid</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>1749042</td>\n",
       "      <td>1538352525000</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>22683</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>279</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>PUT</td>\n",
       "      <td>178.02404</td>\n",
       "      <td>Monster (Album Version)</td>\n",
       "      <td>Skillet</td>\n",
       "      <td>2018-10-01 00:08:45</td>\n",
       "      <td>2018-08-08 13:22:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>200</td>\n",
       "      <td>M</td>\n",
       "      <td>Shlok</td>\n",
       "      <td>paid</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>1749042</td>\n",
       "      <td>1538352703000</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>22683</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>280</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>PUT</td>\n",
       "      <td>232.61995</td>\n",
       "      <td>Seven Nation Army</td>\n",
       "      <td>The White Stripes</td>\n",
       "      <td>2018-10-01 00:11:43</td>\n",
       "      <td>2018-08-08 13:22:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>200</td>\n",
       "      <td>M</td>\n",
       "      <td>Shlok</td>\n",
       "      <td>paid</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>1749042</td>\n",
       "      <td>1538352935000</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>22683</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>281</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>PUT</td>\n",
       "      <td>265.50812</td>\n",
       "      <td>Under The Bridge (Album Version)</td>\n",
       "      <td>Red Hot Chili Peppers</td>\n",
       "      <td>2018-10-01 00:15:35</td>\n",
       "      <td>2018-08-08 13:22:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>200</td>\n",
       "      <td>M</td>\n",
       "      <td>Shlok</td>\n",
       "      <td>paid</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>1749042</td>\n",
       "      <td>1538353200000</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>22683</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>282</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>PUT</td>\n",
       "      <td>471.69261</td>\n",
       "      <td>Circlesong 6</td>\n",
       "      <td>Bobby McFerrin</td>\n",
       "      <td>2018-10-01 00:20:00</td>\n",
       "      <td>2018-08-08 13:22:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      status gender firstName level lastName   userId             ts  \\\n",
       "0        200      M     Shlok  paid  Johnson  1749042  1538352001000   \n",
       "992      200      M     Shlok  paid  Johnson  1749042  1538352525000   \n",
       "1360     200      M     Shlok  paid  Johnson  1749042  1538352703000   \n",
       "1825     200      M     Shlok  paid  Johnson  1749042  1538352935000   \n",
       "2366     200      M     Shlok  paid  Johnson  1749042  1538353200000   \n",
       "\n",
       "           auth      page  sessionId                         location  \\\n",
       "0     Logged In  NextSong      22683  Dallas-Fort Worth-Arlington, TX   \n",
       "992   Logged In  NextSong      22683  Dallas-Fort Worth-Arlington, TX   \n",
       "1360  Logged In  NextSong      22683  Dallas-Fort Worth-Arlington, TX   \n",
       "1825  Logged In  NextSong      22683  Dallas-Fort Worth-Arlington, TX   \n",
       "2366  Logged In  NextSong      22683  Dallas-Fort Worth-Arlington, TX   \n",
       "\n",
       "      itemInSession                                          userAgent method  \\\n",
       "0               278  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...    PUT   \n",
       "992             279  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...    PUT   \n",
       "1360            280  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...    PUT   \n",
       "1825            281  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...    PUT   \n",
       "2366            282  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...    PUT   \n",
       "\n",
       "         length                                    song  \\\n",
       "0     524.32934  Ich mache einen Spiegel - Dream Part 4   \n",
       "992   178.02404                 Monster (Album Version)   \n",
       "1360  232.61995                       Seven Nation Army   \n",
       "1825  265.50812        Under The Bridge (Album Version)   \n",
       "2366  471.69261                            Circlesong 6   \n",
       "\n",
       "                     artist                time        registration  \n",
       "0                 Popol Vuh 2018-10-01 00:00:01 2018-08-08 13:22:21  \n",
       "992                 Skillet 2018-10-01 00:08:45 2018-08-08 13:22:21  \n",
       "1360      The White Stripes 2018-10-01 00:11:43 2018-08-08 13:22:21  \n",
       "1825  Red Hot Chili Peppers 2018-10-01 00:15:35 2018-08-08 13:22:21  \n",
       "2366         Bobby McFerrin 2018-10-01 00:20:00 2018-08-08 13:22:21  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = '/Users/chloevacca/PycharmProjects/PyDataScience/customer churn'\n",
    "df = pd.read_parquet(root + '/train.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82101e8df7462802",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T12:57:35.101074Z",
     "start_time": "2025-12-09T12:57:07.945391Z"
    }
   },
   "outputs": [],
   "source": [
    "object_cols = df.select_dtypes(include=\"object\").columns\n",
    "df[object_cols] = df[object_cols].astype(\"category\")\n",
    "df.drop(columns=['gender', 'firstName', 'lastName', 'location', 'userAgent'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b29221dc3046e1ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T12:58:42.417704Z",
     "start_time": "2025-12-09T12:57:35.176759Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloevacca/PycharmProjects/PyDataScience/kaggle-churn/src/preprocessing.py:155: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  per_day_counts = df_copy.groupby([user_col, 'date']).size().reset_index(name='event_count')\n",
      "/Users/chloevacca/PycharmProjects/PyDataScience/kaggle-churn/src/preprocessing.py:157: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  session_counts = df_copy.groupby([user_col, 'date'])['sessionId'].nunique().reset_index(name='session_count')\n",
      "/Users/chloevacca/PycharmProjects/PyDataScience/kaggle-churn/src/preprocessing.py:164: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  user_registration = df_copy.groupby(user_col)[registration_col].first().reset_index()\n",
      "/Users/chloevacca/PycharmProjects/PyDataScience/kaggle-churn/src/preprocessing.py:175: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  level_per_day = df_copy.groupby([user_col, 'date'])[level_col].last().reset_index()\n",
      "/Users/chloevacca/PycharmProjects/PyDataScience/kaggle-churn/src/preprocessing.py:181: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_aggregated = df_copy.groupby([user_col, 'date', page_col]).size().unstack(fill_value=0).reset_index()\n",
      "/Users/chloevacca/PycharmProjects/PyDataScience/kaggle-churn/src/preprocessing.py:207: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  for user_id, user_data in df_aggregated.groupby(user_col):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>userId</th>\n",
       "      <th>About</th>\n",
       "      <th>Add Friend</th>\n",
       "      <th>Add to Playlist</th>\n",
       "      <th>Cancel</th>\n",
       "      <th>Downgrade</th>\n",
       "      <th>Error</th>\n",
       "      <th>Help</th>\n",
       "      <th>Home</th>\n",
       "      <th>...</th>\n",
       "      <th>Submit Upgrade</th>\n",
       "      <th>Thumbs Down</th>\n",
       "      <th>Thumbs Up</th>\n",
       "      <th>Upgrade</th>\n",
       "      <th>event_count</th>\n",
       "      <th>session_count</th>\n",
       "      <th>active_flag</th>\n",
       "      <th>events_per_session</th>\n",
       "      <th>level</th>\n",
       "      <th>days_since_registration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>1000025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>1000025</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>paid</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>1000025</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>381</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>381.0</td>\n",
       "      <td>paid</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>1000025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>237.0</td>\n",
       "      <td>paid</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>1000025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>paid</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   userId  About  Add Friend  Add to Playlist  Cancel  Downgrade  \\\n",
       "0  2018-10-01  1000025      0           0                0       0          0   \n",
       "1  2018-10-02  1000025      0           3                2       0          1   \n",
       "2  2018-10-03  1000025      0           6               13       0          2   \n",
       "3  2018-10-04  1000025      0           0                5       0          3   \n",
       "4  2018-10-05  1000025      0           0                1       0          2   \n",
       "\n",
       "   Error  Help  Home  ...  Submit Upgrade  Thumbs Down  Thumbs Up  Upgrade  \\\n",
       "0      0     0     0  ...               0            0          0        0   \n",
       "1      0     1     6  ...               1            2          5        1   \n",
       "2      0     2    13  ...               0            3         21        0   \n",
       "3      0     1     9  ...               0            3         12        0   \n",
       "4      0     0     2  ...               0            0          0        0   \n",
       "\n",
       "   event_count  session_count  active_flag  events_per_session  level  \\\n",
       "0            0              0            0                 0.0    NaN   \n",
       "1          120              2            1                60.0   paid   \n",
       "2          381              1            1               381.0   paid   \n",
       "3          237              1            1               237.0   paid   \n",
       "4           27              1            1                27.0   paid   \n",
       "\n",
       "   days_since_registration  \n",
       "0                       83  \n",
       "1                       84  \n",
       "2                       85  \n",
       "3                       86  \n",
       "4                       87  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = aggregate_user_day_activity(df)\n",
    "df_new['userId'] = df_new['userId'].astype(int)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d588f19b489c3ead",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T13:00:13.522602Z",
     "start_time": "2025-12-09T12:58:42.735549Z"
    }
   },
   "outputs": [],
   "source": [
    "df_new = add_rolling_averages(df_new, columns=['Add Friend', 'Add to Playlist', 'Thumbs Down', 'Thumbs Up', 'Error'], n=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b00ade0d488e1880",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T13:00:13.800915Z",
     "start_time": "2025-12-09T13:00:13.565458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>userId</th>\n",
       "      <th>About</th>\n",
       "      <th>Add Friend</th>\n",
       "      <th>Add to Playlist</th>\n",
       "      <th>Cancel</th>\n",
       "      <th>Downgrade</th>\n",
       "      <th>Error</th>\n",
       "      <th>Help</th>\n",
       "      <th>Home</th>\n",
       "      <th>...</th>\n",
       "      <th>active_flag</th>\n",
       "      <th>events_per_session</th>\n",
       "      <th>level</th>\n",
       "      <th>days_since_registration</th>\n",
       "      <th>add_friend_avg_7d</th>\n",
       "      <th>add_to_playlist_avg_7d</th>\n",
       "      <th>thumbs_down_avg_7d</th>\n",
       "      <th>thumbs_up_avg_7d</th>\n",
       "      <th>error_avg_7d</th>\n",
       "      <th>thumbs_ratio_7d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>1000025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>1000025</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>paid</td>\n",
       "      <td>84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-10-03</td>\n",
       "      <td>1000025</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>381.0</td>\n",
       "      <td>paid</td>\n",
       "      <td>85</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-10-04</td>\n",
       "      <td>1000025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>237.0</td>\n",
       "      <td>paid</td>\n",
       "      <td>86</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.83871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>1000025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>paid</td>\n",
       "      <td>87</td>\n",
       "      <td>2.25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.826087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   userId  About  Add Friend  Add to Playlist  Cancel  Downgrade  \\\n",
       "0  2018-10-01  1000025      0           0                0       0          0   \n",
       "1  2018-10-02  1000025      0           3                2       0          1   \n",
       "2  2018-10-03  1000025      0           6               13       0          2   \n",
       "3  2018-10-04  1000025      0           0                5       0          3   \n",
       "4  2018-10-05  1000025      0           0                1       0          2   \n",
       "\n",
       "   Error  Help  Home  ...  active_flag  events_per_session  level  \\\n",
       "0      0     0     0  ...            0                 0.0    NaN   \n",
       "1      0     1     6  ...            1                60.0   paid   \n",
       "2      0     2    13  ...            1               381.0   paid   \n",
       "3      0     1     9  ...            1               237.0   paid   \n",
       "4      0     0     2  ...            1                27.0   paid   \n",
       "\n",
       "   days_since_registration  add_friend_avg_7d  add_to_playlist_avg_7d  \\\n",
       "0                       83                NaN                     NaN   \n",
       "1                       84               0.00                     0.0   \n",
       "2                       85               1.50                     1.0   \n",
       "3                       86               3.00                     5.0   \n",
       "4                       87               2.25                     5.0   \n",
       "\n",
       "   thumbs_down_avg_7d  thumbs_up_avg_7d  error_avg_7d  thumbs_ratio_7d  \n",
       "0                 NaN               NaN           NaN              NaN  \n",
       "1            0.000000          0.000000           0.0             <NA>  \n",
       "2            1.000000          2.500000           0.0         0.714286  \n",
       "3            1.666667          8.666667           0.0          0.83871  \n",
       "4            2.000000          9.500000           0.0         0.826087  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denominator = df_new['thumbs_up_avg_7d'] + df_new['thumbs_down_avg_7d']\n",
    "df_new['thumbs_ratio_7d'] = df_new['thumbs_up_avg_7d'] / denominator.replace(0, pd.NA)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "927ee6fb8879f58c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T13:00:15.312230Z",
     "start_time": "2025-12-09T13:00:13.820876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing cancellation targets for 51 unique dates...\n",
      "\n",
      "Cancellation targets shape: (976140, 3)\n",
      "Sample:\n",
      "    userId  churn_status        date\n",
      "0  1749042             0  2018-10-01\n",
      "1  1563081             0  2018-10-01\n",
      "2  1697168             0  2018-10-01\n",
      "3  1222580             0  2018-10-01\n",
      "4  1714398             0  2018-10-01\n",
      "5  1010522             0  2018-10-01\n",
      "6  1475659             0  2018-10-01\n",
      "7  1558463             0  2018-10-01\n",
      "8  1605667             0  2018-10-01\n",
      "9  1385500             0  2018-10-01\n"
     ]
    }
   ],
   "source": [
    "unique_dates = sorted(df_new['date'].unique())\n",
    "print(f\"Computing cancellation targets for {len(unique_dates)} unique dates...\")\n",
    "\n",
    "cancellation_targets = []\n",
    "df['page'] = df['page'].astype(str)\n",
    "\n",
    "for present_date in unique_dates:\n",
    "    target_df = compute_cancellation(df, present_time=present_date, window_days=10)\n",
    "    target_df['date'] = present_date\n",
    "    cancellation_targets.append(target_df)\n",
    "\n",
    "target_by_date = pd.concat(cancellation_targets, ignore_index=True)\n",
    "target_by_date = target_by_date.rename(columns={'userId': 'userId', 'cancellation_confirmed': 'churn_status'})\n",
    "\n",
    "print(f\"\\nCancellation targets shape: {target_by_date.shape}\")\n",
    "print(f\"Sample:\")\n",
    "print(target_by_date.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e8cb630a088045ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df_new = pd.read_csv(root + '/data/df_transformed.csv')\n",
    "# target_by_date = pd.read_csv(root + '/data/churn_status.csv')\n",
    "#\n",
    "# df_new.to_csv(root + '/data/df_transformed.csv', index=False)\n",
    "# # target_by_date.to_csv(root + '/data/churn_status.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01aa0be15ddd888",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on int64 and object columns for key 'userId'. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m df_new[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(df_new[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      2\u001b[39m target_by_date[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(target_by_date[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df_train = \u001b[43mdf_new\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_by_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43muserId\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mleft\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mChurn distribution:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(df_train[\u001b[33m'\u001b[39m\u001b[33mchurn_status\u001b[39m\u001b[33m'\u001b[39m].value_counts())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/PyDataScience/.venv/lib/python3.13/site-packages/pandas/core/frame.py:10839\u001b[39m, in \u001b[36mDataFrame.merge\u001b[39m\u001b[34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m  10820\u001b[39m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m  10821\u001b[39m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents=\u001b[32m2\u001b[39m)\n\u001b[32m  10822\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmerge\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m  10835\u001b[39m     validate: MergeValidate | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m  10836\u001b[39m ) -> DataFrame:\n\u001b[32m  10837\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreshape\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmerge\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[32m> \u001b[39m\u001b[32m10839\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  10840\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m  10841\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10843\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10845\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10846\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10848\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10849\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10850\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10851\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10852\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  10853\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/PyDataScience/.venv/lib/python3.13/site-packages/pandas/core/reshape/merge.py:170\u001b[39m, in \u001b[36mmerge\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    155\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[32m    156\u001b[39m         left_df,\n\u001b[32m    157\u001b[39m         right_df,\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         copy=copy,\n\u001b[32m    168\u001b[39m     )\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     op = \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result(copy=copy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/PyDataScience/.venv/lib/python3.13/site-packages/pandas/core/reshape/merge.py:807\u001b[39m, in \u001b[36m_MergeOperation.__init__\u001b[39m\u001b[34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[39m\n\u001b[32m    803\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_tolerance(\u001b[38;5;28mself\u001b[39m.left_join_keys)\n\u001b[32m    805\u001b[39m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[32m    806\u001b[39m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m807\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    809\u001b[39m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[32m    810\u001b[39m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[32m    811\u001b[39m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[32m    812\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/PyDataScience/.venv/lib/python3.13/site-packages/pandas/core/reshape/merge.py:1509\u001b[39m, in \u001b[36m_MergeOperation._maybe_coerce_merge_keys\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1503\u001b[39m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[32m   1504\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m   1505\u001b[39m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[32m   1506\u001b[39m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1507\u001b[39m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[32m   1508\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1509\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1511\u001b[39m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[32m   1512\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk.dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk.dtype):\n",
      "\u001b[31mValueError\u001b[39m: You are trying to merge on int64 and object columns for key 'userId'. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "# Convert date column to datetime if it's not already\n",
    "if df_new['date'].dtype == 'object' or str(df_new['date'].dtype).startswith('category'):\n",
    "    df_new['date'] = pd.to_datetime(df_new['date'])\n",
    "elif not pd.api.types.is_datetime64_any_dtype(df_new['date']):\n",
    "    df_new['date'] = pd.to_datetime(df_new['date'])\n",
    "\n",
    "# Convert df['page'] to string to avoid categorical issues in compute_cancellation\n",
    "df['page'] = df['page'].astype(str)\n",
    "\n",
    "unique_dates = sorted(df_new['date'].unique())\n",
    "print(f\"Computing cancellation targets for {len(unique_dates)} unique dates...\")\n",
    "\n",
    "cancellation_targets = []\n",
    "\n",
    "for present_date in unique_dates:\n",
    "    target_df = compute_cancellation(df, present_time=present_date, window_days=10)\n",
    "    target_df['date'] = present_date\n",
    "    cancellation_targets.append(target_df)\n",
    "\n",
    "target_by_date = pd.concat(cancellation_targets, ignore_index=True)\n",
    "target_by_date = target_by_date.rename(columns={'userId': 'userId', 'cancellation_confirmed': 'churn_status'})\n",
    "\n",
    "print(f\"\\nCancellation targets shape: {target_by_date.shape}\")\n",
    "print(f\"Sample:\")\n",
    "print(target_by_date.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78856b915f339665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (780912, 30)\n",
      "Test set size: (195228, 30)\n",
      "Feature columns (30): ['About', 'Add Friend', 'Add to Playlist', 'Cancel', 'Downgrade', 'Error', 'Help', 'Home', 'Logout', 'NextSong', 'Roll Advert', 'Save Settings', 'Settings', 'Submit Downgrade', 'Submit Upgrade', 'Thumbs Down', 'Thumbs Up', 'Upgrade', 'event_count', 'session_count', 'active_flag', 'events_per_session', 'level', 'days_since_registration', 'add_friend_avg_7d', 'add_to_playlist_avg_7d', 'thumbs_down_avg_7d', 'thumbs_up_avg_7d', 'error_avg_7d', 'thumbs_ratio_7d']\n",
      "\n",
      "Data types after fixes:\n",
      "About                        int64\n",
      "Add Friend                   int64\n",
      "Add to Playlist              int64\n",
      "Cancel                       int64\n",
      "Downgrade                    int64\n",
      "Error                        int64\n",
      "Help                         int64\n",
      "Home                         int64\n",
      "Logout                       int64\n",
      "NextSong                     int64\n",
      "Roll Advert                  int64\n",
      "Save Settings                int64\n",
      "Settings                     int64\n",
      "Submit Downgrade             int64\n",
      "Submit Upgrade               int64\n",
      "Thumbs Down                  int64\n",
      "Thumbs Up                    int64\n",
      "Upgrade                      int64\n",
      "event_count                  int64\n",
      "session_count                int64\n",
      "active_flag                  int64\n",
      "events_per_session         float64\n",
      "level                        int64\n",
      "days_since_registration      int64\n",
      "add_friend_avg_7d          float64\n",
      "add_to_playlist_avg_7d     float64\n",
      "thumbs_down_avg_7d         float64\n",
      "thumbs_up_avg_7d           float64\n",
      "error_avg_7d               float64\n",
      "thumbs_ratio_7d            float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Split data and define variables for modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define feature columns (exclude userId, date, and target)\n",
    "feature_cols = [col for col in df_train.columns if col not in ['userId', 'date', 'churn_status']]\n",
    "\n",
    "# Separate features and target\n",
    "X = df_train[feature_cols].copy()\n",
    "y = df_train['churn_status']\n",
    "\n",
    "# Fix data types for XGBoost compatibility\n",
    "# Convert 'level' category to numeric (0 for 'free', 1 for 'paid')\n",
    "if 'level' in X.columns:\n",
    "    X['level'] = (X['level'] == 'paid').astype(int)\n",
    "\n",
    "# Convert thumbs_ratio_7d from object to float\n",
    "if 'thumbs_ratio_7d' in X.columns:\n",
    "    X['thumbs_ratio_7d'] = pd.to_numeric(X['thumbs_ratio_7d'], errors='coerce').fillna(0)\n",
    "\n",
    "# Split into train and test sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "print(f\"Feature columns ({len(feature_cols)}): {feature_cols}\")\n",
    "print(f\"\\nData types after fixes:\")\n",
    "print(X_train.dtypes)\n",
    "\n",
    "# For predictions on final test data\n",
    "X_test_pred = X_test\n",
    "df_test_final = df_train.iloc[X_test.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a335d0e7669b4846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression and generate predictions\n",
    "import xgboost as xgb\n",
    "import src.modeling\n",
    "reload(src.modeling)\n",
    "from src.modeling import (\n",
    "    train_xgboost,\n",
    "    evaluate_model,\n",
    "    get_feature_importance,\n",
    "    make_predictions,\n",
    "    create_submission,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cfefe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = range(1, 21)\n",
    "train_rmse = []\n",
    "test_rmse = []\n",
    "best_depth = None\n",
    "best_rmse = float('inf')\n",
    "\n",
    "for depth in range(1, 21):\n",
    "    xg = XGBClassifier(max_depth=depth, random_state=42)\n",
    "    xg.fit(X_train, y_train)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, xg.predict(X_test)))\n",
    "    \n",
    "    train_rmse.append(np.sqrt(mean_squared_error(y_train, xg.predict(X_train))))\n",
    "    test_rmse.append(np.sqrt(mean_squared_error(y_test, xg.predict(X_test))))\n",
    "    \n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_depth = depth\n",
    "\n",
    "print(f\"Best depth: {best_depth}, RMSE: {best_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4554db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph for best depth\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(10, 6))\n",
    "plt.plot(max_depths, train_rmse, label='Train RMSE', marker='o')\n",
    "plt.plot(max_depths, test_rmse, label='Test RMSE', marker='s')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7df3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "# xgb_model = train_xgboost(X_train, y_train)\n",
    "# xgb_results = evaluate_model(xgb_model, X_test, y_test)\n",
    "# xgb_feature_importance = get_feature_importance(xgb_model, feature_cols, top_n=10)\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=None,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "# Load and preprocess test data to mirror train\n",
    "print(\"\\nLoading test data and applying preprocessing...\")\n",
    "df_test_raw = pd.read_parquet(root + '/test.parquet')\n",
    "\n",
    "object_cols_test = df_test_raw.select_dtypes(include=\"object\").columns\n",
    "df_test_raw[object_cols_test] = df_test_raw[object_cols_test].astype(\"category\")\n",
    "\n",
    "df_test_raw = df_test_raw.drop(columns=['gender', 'firstName', 'lastName', 'location', 'userAgent'], errors='ignore')\n",
    "\n",
    "df_test_agg = aggregate_user_day_activity(df_test_raw)\n",
    "df_test_agg['userId'] = df_test_agg['userId'].astype(int)\n",
    "\n",
    "df_test_agg = add_rolling_averages(\n",
    "    df_test_agg,\n",
    "    columns=['Add Friend', 'Add to Playlist', 'Thumbs Down', 'Thumbs Up', 'Error'],\n",
    "    n=7\n",
    ")\n",
    "\n",
    "denominator_test = df_test_agg['thumbs_up_avg_7d'] + df_test_agg['thumbs_down_avg_7d']\n",
    "df_test_agg['thumbs_ratio_7d'] = df_test_agg['thumbs_up_avg_7d'] / denominator_test.replace(0, pd.NA)\n",
    "\n",
    "# Use the most recent date per user for prediction\n",
    "df_test_latest = df_test_agg.sort_values('date').groupby('userId', as_index=False).tail(1)\n",
    "\n",
    "# Align test features to the training feature set\n",
    "X_test_submission = df_test_latest.reindex(columns=feature_cols, fill_value=0)\n",
    "\n",
    "# Apply same data type fixes as training data\n",
    "if 'level' in X_test_submission.columns:\n",
    "    X_test_submission['level'] = (X_test_submission['level'] == 'paid').astype(int)\n",
    "\n",
    "if 'thumbs_ratio_7d' in X_test_submission.columns:\n",
    "    X_test_submission['thumbs_ratio_7d'] = pd.to_numeric(X_test_submission['thumbs_ratio_7d'], errors='coerce').fillna(0)\n",
    "\n",
    "print(f\"Test submission matrix shape: {X_test_submission.shape}\")\n",
    "print(f\"Test data types: {X_test_submission.dtypes.value_counts()}\")\n",
    "\n",
    "# Predict and write submission\n",
    "xgb_test_predictions, xgb_test_proba = make_predictions(xgb_model, X_test_submission)\n",
    "xgb_submission_final = create_submission(\n",
    "    df_test_latest['userId'].values,\n",
    "    xgb_test_predictions,\n",
    "    output_path=root + '/submission_xgb_logloss.csv'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
